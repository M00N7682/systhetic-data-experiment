{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# T-cKS (Tail-Conditional KS Distance) ì‹¤í—˜\n",
        "\n",
        "**ë³´í—˜ í•©ì„± ë°ì´í„° í‰ê°€ë¥¼ ìœ„í•œ T-cKS ì§€í‘œ ê²€ì¦ ì‹¤í—˜**\n",
        "\n",
        "## ëª©ì°¨\n",
        "1. ë°ì´í„° ë¡œë”© ë° íƒìƒ‰\n",
        "2. Loss ë¶„í¬ ë¶„ì„\n",
        "3. ì¡°ê±´ ë³€ìˆ˜ ì„ íƒ\n",
        "4. Failure Mode Injection\n",
        "5. Experiment 1: Controlled Failure Mode\n",
        "6. ê²°ê³¼ ì‹œê°í™”\n",
        "7. Experiment 2: Sensitivity Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (ì²˜ìŒ í•œ ë²ˆë§Œ ì‹¤í–‰)\n",
        "# !pip install numpy pandas scipy matplotlib seaborn\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from scipy.io import arff\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import Tuple, Dict, List\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ìŠ¤íƒ€ì¼ ì„¤ì •\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 11\n",
        "\n",
        "# ìƒ‰ìƒ íŒ”ë ˆíŠ¸\n",
        "COLORS = {\n",
        "    'mKS': '#27ae60',    # ë…¹ìƒ‰\n",
        "    'cKS': '#3498db',    # íŒŒë‘\n",
        "    'T-cKS': '#e74c3c',  # ë¹¨ê°•\n",
        "}\n",
        "\n",
        "print(\"âœ… íŒ¨í‚¤ì§€ ë¡œë“œ ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ë°ì´í„° ë¡œë”©\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ARFF íŒŒì¼ ë¡œë“œ\n",
        "def load_arff_data(file_path: str) -> pd.DataFrame:\n",
        "    \"\"\"ARFF íŒŒì¼ì„ DataFrameìœ¼ë¡œ ë¡œë“œ\"\"\"\n",
        "    data, meta = arff.loadarff(file_path)\n",
        "    df = pd.DataFrame(data)\n",
        "    \n",
        "    # bytesë¥¼ stringìœ¼ë¡œ ë³€í™˜\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == object:\n",
        "            df[col] = df[col].str.decode('utf-8')\n",
        "    \n",
        "    return df\n",
        "\n",
        "# ë°ì´í„° ë¡œë“œ\n",
        "df = load_arff_data(\"dataset.arff\")\n",
        "\n",
        "print(f\"ğŸ“Š ë°ì´í„° ë¡œë“œ ì™„ë£Œ!\")\n",
        "print(f\"   - ìƒ˜í”Œ ìˆ˜: {len(df):,}\")\n",
        "print(f\"   - ë³€ìˆ˜ ìˆ˜: {len(df.columns)}\")\n",
        "print(f\"\\nì²˜ìŒ 5ê°œ í–‰:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Loss ë¶„í¬ ë¶„ì„\n",
        "\n",
        "Heavy-tailed ë¶„í¬ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loss ê¸°ë³¸ í†µê³„ëŸ‰\n",
        "loss = df['loss']\n",
        "\n",
        "print(\"ğŸ“ˆ Loss ë¶„í¬ í†µê³„ëŸ‰\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"ìƒ˜í”Œ ìˆ˜:     {len(loss):,}\")\n",
        "print(f\"í‰ê· :        {loss.mean():,.2f}\")\n",
        "print(f\"ì¤‘ì•™ê°’:      {loss.median():,.2f}\")\n",
        "print(f\"í‘œì¤€í¸ì°¨:    {loss.std():,.2f}\")\n",
        "print(f\"ìµœì†Œê°’:      {loss.min():,.2f}\")\n",
        "print(f\"ìµœëŒ€ê°’:      {loss.max():,.2f}\")\n",
        "print(f\"ì™œë„:        {stats.skew(loss):.2f}\")\n",
        "print(f\"ì²¨ë„:        {stats.kurtosis(loss):.2f}\")\n",
        "print()\n",
        "print(\"ğŸ“Š ë¶„ìœ„ìˆ˜:\")\n",
        "for q in [0.50, 0.75, 0.90, 0.95, 0.99, 0.999]:\n",
        "    print(f\"   {q*100:.1f}%: {loss.quantile(q):,.2f}\")\n",
        "\n",
        "# Heavy-tailed íŒì •\n",
        "is_heavy_tailed = (stats.skew(loss) > 1.0) and (stats.kurtosis(loss) > 3.0)\n",
        "print(f\"\\nâœ… Heavy-tailed ì—¬ë¶€: {is_heavy_tailed}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loss ë¶„í¬ ì‹œê°í™”\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# 1. íˆìŠ¤í† ê·¸ë¨\n",
        "ax1 = axes[0]\n",
        "ax1.hist(loss, bins=100, color='steelblue', alpha=0.7, edgecolor='white')\n",
        "ax1.axvline(loss.mean(), color='red', linestyle='--', label=f'Mean: {loss.mean():,.0f}')\n",
        "ax1.axvline(loss.median(), color='orange', linestyle='--', label=f'Median: {loss.median():,.0f}')\n",
        "ax1.set_xlabel('Loss')\n",
        "ax1.set_ylabel('Frequency')\n",
        "ax1.set_title('Loss Distribution')\n",
        "ax1.legend()\n",
        "\n",
        "# 2. Log ìŠ¤ì¼€ì¼ íˆìŠ¤í† ê·¸ë¨\n",
        "ax2 = axes[1]\n",
        "ax2.hist(np.log1p(loss), bins=100, color='seagreen', alpha=0.7, edgecolor='white')\n",
        "ax2.set_xlabel('Log(1 + Loss)')\n",
        "ax2.set_ylabel('Frequency')\n",
        "ax2.set_title('Log-transformed Loss Distribution')\n",
        "\n",
        "# 3. Tail ì˜ì—­ í™•ëŒ€\n",
        "ax3 = axes[2]\n",
        "q95 = loss.quantile(0.95)\n",
        "tail_data = loss[loss > q95]\n",
        "ax3.hist(tail_data, bins=50, color='coral', alpha=0.7, edgecolor='white')\n",
        "ax3.axvline(q95, color='red', linestyle='--', label=f'95th percentile: {q95:,.0f}')\n",
        "ax3.set_xlabel('Loss')\n",
        "ax3.set_ylabel('Frequency')\n",
        "ax3.set_title(f'Tail Distribution (top 5%, n={len(tail_data):,})')\n",
        "ax3.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. ì¡°ê±´ ë³€ìˆ˜(Z) ì„ íƒ\n",
        "\n",
        "T-cKS ê³„ì‚°ì„ ìœ„í•œ ì¡°ê±´ ë³€ìˆ˜ë¥¼ ì„ íƒí•©ë‹ˆë‹¤. ì ì ˆí•œ ê·¸ë£¹ ìˆ˜(2~10ê°œ)ì™€ ì¶©ë¶„í•œ ìƒ˜í”Œ ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì¡°ê±´ ë³€ìˆ˜ í›„ë³´ ë¶„ì„\n",
        "candidate_cols = ['cat79', 'cat80', 'cat81', 'cat82', 'cat83', 'cat87', 'cat89']\n",
        "\n",
        "print(\"ğŸ“‹ ì¡°ê±´ ë³€ìˆ˜ í›„ë³´ ë¶„ì„\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "results = []\n",
        "for col in candidate_cols:\n",
        "    if col not in df.columns:\n",
        "        continue\n",
        "    \n",
        "    group_stats = df.groupby(col)['loss'].agg(['count', 'mean', 'std'])\n",
        "    n_groups = len(group_stats)\n",
        "    min_count = group_stats['count'].min()\n",
        "    mean_range = group_stats['mean'].max() - group_stats['mean'].min()\n",
        "    \n",
        "    suitable = (2 <= n_groups <= 10) and (min_count >= 1000)\n",
        "    status = \"âœ… ì í•©\" if suitable else \"âŒ ë¶€ì í•©\"\n",
        "    \n",
        "    results.append({\n",
        "        'col': col,\n",
        "        'n_groups': n_groups,\n",
        "        'min_count': min_count,\n",
        "        'mean_range': mean_range,\n",
        "        'suitable': suitable\n",
        "    })\n",
        "    \n",
        "    print(f\"{col}: {n_groups}ê°œ ê·¸ë£¹, ìµœì†Œ ìƒ˜í”Œ={min_count:,}, í‰ê·  ë²”ìœ„={mean_range:.1f} [{status}]\")\n",
        "\n",
        "# ê²°ê³¼ DataFrame\n",
        "cond_df = pd.DataFrame(results)\n",
        "print(\"\\nì¶”ì²œ ì¡°ê±´ ë³€ìˆ˜:\")\n",
        "print(cond_df[cond_df['suitable']][['col', 'n_groups', 'min_count']].to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì¡°ê±´ ë³€ìˆ˜ ì„ íƒ (ì í•©í•œ ì²« ë²ˆì§¸ ë³€ìˆ˜ ì‚¬ìš©)\n",
        "CONDITION_COL = cond_df[cond_df['suitable']]['col'].iloc[0] if cond_df['suitable'].any() else 'cat79'\n",
        "print(f\"ğŸ¯ ì„ íƒëœ ì¡°ê±´ ë³€ìˆ˜: {CONDITION_COL}\")\n",
        "\n",
        "# ì¡°ê±´ë³„ Loss ë¶„í¬ ì‹œê°í™”\n",
        "groups = df[CONDITION_COL].unique()\n",
        "n_groups = len(groups)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# 1. ì¡°ê±´ë³„ ë°•ìŠ¤í”Œë¡¯\n",
        "ax1 = axes[0]\n",
        "df.boxplot(column='loss', by=CONDITION_COL, ax=ax1)\n",
        "ax1.set_title(f'Loss Distribution by {CONDITION_COL}')\n",
        "ax1.set_xlabel(CONDITION_COL)\n",
        "ax1.set_ylabel('Loss')\n",
        "plt.suptitle('')\n",
        "\n",
        "# 2. ì¡°ê±´ë³„ ë°€ë„ í”Œë¡¯ (log scale)\n",
        "ax2 = axes[1]\n",
        "for g in sorted(groups):\n",
        "    subset = df[df[CONDITION_COL] == g]['loss']\n",
        "    ax2.hist(np.log1p(subset), bins=50, alpha=0.5, label=f'{CONDITION_COL}={g} (n={len(subset):,})')\n",
        "ax2.set_xlabel('Log(1 + Loss)')\n",
        "ax2.set_ylabel('Frequency')\n",
        "ax2.set_title(f'Log Loss Distribution by {CONDITION_COL}')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ì¡°ê±´ë³„ í†µê³„\n",
        "print(f\"\\nğŸ“Š {CONDITION_COL}ë³„ í†µê³„:\")\n",
        "print(df.groupby(CONDITION_COL)['loss'].describe().round(2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. ë©”íŠ¸ë¦­ í•¨ìˆ˜ ì •ì˜\n",
        "\n",
        "- **mKS**: Marginal KS (ì „ì²´ ë¶„í¬ ë¹„êµ)\n",
        "- **cKS**: Conditional KS (ì¡°ê±´ë³„ ì „ì²´ ë¶„í¬ ë¹„êµ)\n",
        "- **T-cKS**: Tail-Conditional KS (ì¡°ê±´ë³„ tail ë¶„í¬ë§Œ ë¹„êµ) â­\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_mks(Y_real: np.ndarray, Y_synth: np.ndarray) -> float:\n",
        "    \"\"\"Marginal KS: ì „ì²´ Y ë¶„í¬ ë¹„êµ\"\"\"\n",
        "    ks_stat, _ = stats.ks_2samp(Y_real, Y_synth)\n",
        "    return ks_stat\n",
        "\n",
        "\n",
        "def compute_cks(df_real: pd.DataFrame, \n",
        "                df_synth: pd.DataFrame,\n",
        "                loss_col: str = \"loss\",\n",
        "                condition_col: str = \"cat79\") -> float:\n",
        "    \"\"\"Conditional KS: ì¡°ê±´ë³„ ì „ì²´ ë¶„í¬ ë¹„êµ í›„ ê°€ì¤‘ í‰ê· \"\"\"\n",
        "    conditions = df_real[condition_col].unique()\n",
        "    ks_values = []\n",
        "    weights = []\n",
        "    \n",
        "    for z in conditions:\n",
        "        Y_real_z = df_real[df_real[condition_col] == z][loss_col].values\n",
        "        Y_synth_z = df_synth[df_synth[condition_col] == z][loss_col].values\n",
        "        \n",
        "        if len(Y_real_z) == 0 or len(Y_synth_z) == 0:\n",
        "            continue\n",
        "            \n",
        "        ks_stat, _ = stats.ks_2samp(Y_real_z, Y_synth_z)\n",
        "        ks_values.append(ks_stat)\n",
        "        weights.append(len(Y_real_z))\n",
        "    \n",
        "    if not ks_values:\n",
        "        return np.nan\n",
        "    \n",
        "    return np.average(ks_values, weights=weights)\n",
        "\n",
        "\n",
        "def compute_tcks(df_real: pd.DataFrame,\n",
        "                 df_synth: pd.DataFrame,\n",
        "                 tau_q: float,\n",
        "                 loss_col: str = \"loss\",\n",
        "                 condition_col: str = \"cat79\",\n",
        "                 min_tail_n: int = 30) -> float:\n",
        "    \"\"\"\n",
        "    â­ Tail-Conditional KS: ì¡°ê±´ë³„ tail ë¶„í¬ë§Œ ë¹„êµ\n",
        "    \n",
        "    í•µì‹¬: ë™ì¼í•œ tau_q (ì‹¤ì œ ë°ì´í„° ê¸°ì¤€)ë¥¼ ì–‘ìª½ì— ì ìš©\n",
        "    \"\"\"\n",
        "    conditions = df_real[condition_col].unique()\n",
        "    ks_values = []\n",
        "    weights = []\n",
        "    \n",
        "    for z in conditions:\n",
        "        # Tail subset í•„í„°ë§\n",
        "        Y_real_tail = df_real[\n",
        "            (df_real[condition_col] == z) & (df_real[loss_col] > tau_q)\n",
        "        ][loss_col].values\n",
        "        \n",
        "        Y_synth_tail = df_synth[\n",
        "            (df_synth[condition_col] == z) & (df_synth[loss_col] > tau_q)\n",
        "        ][loss_col].values\n",
        "        \n",
        "        # ìµœì†Œ ìƒ˜í”Œ ìˆ˜ ì²´í¬\n",
        "        if len(Y_real_tail) < min_tail_n or len(Y_synth_tail) < min_tail_n:\n",
        "            continue\n",
        "        \n",
        "        ks_stat, _ = stats.ks_2samp(Y_real_tail, Y_synth_tail)\n",
        "        ks_values.append(ks_stat)\n",
        "        weights.append(len(Y_real_tail))\n",
        "    \n",
        "    if not ks_values:\n",
        "        return np.nan\n",
        "    \n",
        "    return np.average(ks_values, weights=weights)\n",
        "\n",
        "\n",
        "print(\"âœ… ë©”íŠ¸ë¦­ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Failure Mode Injection\n",
        "\n",
        "íŠ¹ì • ì¡°ê±´ì˜ tail ë¶„í¬ë§Œ ì˜ë„ì ìœ¼ë¡œ ì™œê³¡í•©ë‹ˆë‹¤.\n",
        "\n",
        "- **Winsorization**: tail ê°’ì„ thresholdë¡œ ì ˆë‹¨\n",
        "- **Thinning**: tail ìƒ˜í”Œì„ non-tail ìƒ˜í”Œë¡œ ëŒ€ì²´\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def inject_tail_distortion(base_df: pd.DataFrame,\n",
        "                           target_condition: str,\n",
        "                           tau_q: float,\n",
        "                           method: str,\n",
        "                           strength: float,\n",
        "                           loss_col: str = \"loss\",\n",
        "                           condition_col: str = \"cat79\",\n",
        "                           random_seed: int = 42) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    íŠ¹ì • ì¡°ê±´ì˜ tail ë¶„í¬ë§Œ ì™œê³¡\n",
        "    \n",
        "    âš ï¸ base_dfëŠ” ì ˆëŒ€ ìˆ˜ì •í•˜ì§€ ì•ŠìŒ (copy í›„ ì‘ì—…)\n",
        "    \n",
        "    Args:\n",
        "        base_df: ì›ë³¸ ë°ì´í„°\n",
        "        target_condition: ì™œê³¡ ëŒ€ìƒ ì¡°ê±´ ê°’\n",
        "        tau_q: tail threshold\n",
        "        method: \"winsorization\" or \"thinning\"\n",
        "        strength: ì™œê³¡ ê°•ë„ (0.0 ~ 1.0)\n",
        "    \"\"\"\n",
        "    np.random.seed(random_seed)\n",
        "    distorted_df = base_df.copy()\n",
        "    \n",
        "    # ëŒ€ìƒ ë§ˆìŠ¤í¬: íŠ¹ì • ì¡°ê±´ AND tail ì˜ì—­\n",
        "    mask = (distorted_df[condition_col] == target_condition) & \\\n",
        "           (distorted_df[loss_col] > tau_q)\n",
        "    \n",
        "    n_target = mask.sum()\n",
        "    \n",
        "    if n_target == 0 or strength == 0.0:\n",
        "        return distorted_df\n",
        "    \n",
        "    target_indices = distorted_df[mask].index.tolist()\n",
        "    n_to_distort = int(n_target * strength)\n",
        "    \n",
        "    if n_to_distort == 0:\n",
        "        return distorted_df\n",
        "    \n",
        "    distort_indices = np.random.choice(target_indices, size=n_to_distort, replace=False)\n",
        "    \n",
        "    if method == \"winsorization\":\n",
        "        # Tail ê°’ì„ tau_që¡œ ì ˆë‹¨\n",
        "        distorted_df.loc[distort_indices, loss_col] = tau_q\n",
        "        \n",
        "    elif method == \"thinning\":\n",
        "        # Tail ìƒ˜í”Œì„ ê°™ì€ ì¡°ê±´ì˜ non-tailë¡œ ëŒ€ì²´\n",
        "        non_tail_pool = distorted_df[\n",
        "            (distorted_df[condition_col] == target_condition) & \n",
        "            (distorted_df[loss_col] <= tau_q)\n",
        "        ]\n",
        "        \n",
        "        if len(non_tail_pool) > 0:\n",
        "            replacement_values = non_tail_pool[loss_col].sample(\n",
        "                n=n_to_distort, replace=True, random_state=random_seed\n",
        "            ).values\n",
        "            distorted_df.loc[distort_indices, loss_col] = replacement_values\n",
        "    \n",
        "    return distorted_df\n",
        "\n",
        "\n",
        "print(\"âœ… Failure Mode Injection í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Experiment 1: Controlled Failure Mode Simulation\n",
        "\n",
        "ì‹¤í—˜ ê·¸ë¦¬ë“œ:\n",
        "- **ë°©ë²•**: winsorization, thinning\n",
        "- **ì™œê³¡ ê°•ë„**: 0.0, 0.2, 0.4, 0.6, 0.8, 1.0\n",
        "- **q ê°’**: 0.90, 0.95, 0.99\n",
        "- **ë°˜ë³µ ì‹œë“œ**: 5íšŒ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì‹¤í—˜ ì„¤ì •\n",
        "LOSS_COL = 'loss'\n",
        "MIN_TAIL_N = 30\n",
        "\n",
        "# íƒ€ê²Ÿ ì¡°ê±´ ì„ íƒ (ê°€ì¥ ìƒ˜í”Œ ìˆ˜ê°€ ì ì€ ê·¸ë£¹ - íš¨ê³¼ê°€ ì˜ ë³´ì„)\n",
        "group_counts = df.groupby(CONDITION_COL).size()\n",
        "TARGET_CONDITION = group_counts.idxmin()\n",
        "\n",
        "print(f\"ğŸ¯ ì‹¤í—˜ ì„¤ì •\")\n",
        "print(f\"   - ì¡°ê±´ ë³€ìˆ˜: {CONDITION_COL}\")\n",
        "print(f\"   - ì™œê³¡ ëŒ€ìƒ ì¡°ê±´: {TARGET_CONDITION} (n={group_counts[TARGET_CONDITION]:,})\")\n",
        "print(f\"   - ì „ì²´ ìƒ˜í”Œ ìˆ˜: {len(df):,}\")\n",
        "\n",
        "# ì‹¤í—˜ ê·¸ë¦¬ë“œ\n",
        "methods = ['winsorization', 'thinning']\n",
        "strengths = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
        "q_values = [0.90, 0.95, 0.99]\n",
        "seeds = [42, 123, 456, 789, 1024]\n",
        "\n",
        "total_runs = len(methods) * len(strengths) * len(q_values) * len(seeds)\n",
        "print(f\"   - ì´ ì‹¤í—˜ ìˆ˜: {total_runs}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "# ì‹¤í—˜ ì‹¤í–‰\n",
        "results = []\n",
        "run_id = 0\n",
        "\n",
        "print(\"ğŸ”¬ ì‹¤í—˜ ì‹œì‘...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for method in methods:\n",
        "    for strength in strengths:\n",
        "        for q in q_values:\n",
        "            for seed in seeds:\n",
        "                run_id += 1\n",
        "                \n",
        "                # Tail threshold (base ë°ì´í„° ê¸°ì¤€)\n",
        "                tau_q = df[LOSS_COL].quantile(q)\n",
        "                \n",
        "                # ì™œê³¡ ë°ì´í„° ìƒì„±\n",
        "                distorted_df = inject_tail_distortion(\n",
        "                    base_df=df,\n",
        "                    target_condition=TARGET_CONDITION,\n",
        "                    tau_q=tau_q,\n",
        "                    method=method,\n",
        "                    strength=strength,\n",
        "                    loss_col=LOSS_COL,\n",
        "                    condition_col=CONDITION_COL,\n",
        "                    random_seed=seed\n",
        "                )\n",
        "                \n",
        "                # ë©”íŠ¸ë¦­ ê³„ì‚°\n",
        "                mks = compute_mks(df[LOSS_COL].values, distorted_df[LOSS_COL].values)\n",
        "                cks = compute_cks(df, distorted_df, LOSS_COL, CONDITION_COL)\n",
        "                tcks = compute_tcks(df, distorted_df, tau_q, LOSS_COL, CONDITION_COL, MIN_TAIL_N)\n",
        "                \n",
        "                results.append({\n",
        "                    'run_id': run_id,\n",
        "                    'method': method,\n",
        "                    'strength': strength,\n",
        "                    'q': q,\n",
        "                    'seed': seed,\n",
        "                    'tau_q': tau_q,\n",
        "                    'mKS': mks,\n",
        "                    'cKS': cks,\n",
        "                    'T-cKS': tcks\n",
        "                })\n",
        "                \n",
        "                if run_id % 30 == 0:\n",
        "                    print(f\"   ì§„í–‰: {run_id}/{total_runs}\")\n",
        "\n",
        "# ê²°ê³¼ DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(f\"âœ… ì‹¤í—˜ ì™„ë£Œ! ì´ {len(results_df)} runs\")\n",
        "results_df.head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. ê²°ê³¼ ì‹œê°í™”\n",
        "\n",
        "### 7.1 í•µì‹¬ ê²°ê³¼: ì™œê³¡ ê°•ë„ë³„ ë©”íŠ¸ë¦­ ë¹„êµ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í•µì‹¬ ê·¸ë˜í”„: ì™œê³¡ ê°•ë„ë³„ ë©”íŠ¸ë¦­ ë¹„êµ (q=0.95)\n",
        "q_focus = 0.95\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "for idx, method in enumerate(['winsorization', 'thinning']):\n",
        "    ax = axes[idx]\n",
        "    \n",
        "    df_method = results_df[(results_df['q'] == q_focus) & (results_df['method'] == method)]\n",
        "    grouped = df_method.groupby('strength')[['mKS', 'cKS', 'T-cKS']].agg(['mean', 'std'])\n",
        "    \n",
        "    strengths = grouped.index.values\n",
        "    \n",
        "    for metric, color in COLORS.items():\n",
        "        means = grouped[(metric, 'mean')].values\n",
        "        stds = grouped[(metric, 'std')].values\n",
        "        \n",
        "        ax.plot(strengths, means, 'o-', label=metric, color=color, linewidth=2.5, markersize=10)\n",
        "        ax.fill_between(strengths, means - stds, means + stds, alpha=0.15, color=color)\n",
        "    \n",
        "    ax.set_xlabel('Distortion Strength', fontsize=12)\n",
        "    ax.set_ylabel('KS Distance', fontsize=12)\n",
        "    ax.set_title(f'{method.capitalize()} (q={q_focus})', fontsize=14, fontweight='bold')\n",
        "    ax.legend(loc='upper left', fontsize=11)\n",
        "    ax.set_xlim(-0.05, 1.05)\n",
        "    ax.set_ylim(0, None)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('ğŸ“Š Metric Comparison by Distortion Strength', fontsize=16, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2 íˆíŠ¸ë§µ: q vs strength\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# T-cKS íˆíŠ¸ë§µ\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
        "\n",
        "for idx, method in enumerate(['winsorization', 'thinning']):\n",
        "    ax = axes[idx]\n",
        "    \n",
        "    pivot = results_df[results_df['method'] == method].pivot_table(\n",
        "        values='T-cKS', \n",
        "        index='q', \n",
        "        columns='strength', \n",
        "        aggfunc='mean'\n",
        "    )\n",
        "    \n",
        "    sns.heatmap(pivot, annot=True, fmt='.3f', cmap='Reds', ax=ax,\n",
        "                cbar_kws={'label': 'T-cKS'}, vmin=0)\n",
        "    \n",
        "    ax.set_title(f'T-cKS Heatmap: {method.capitalize()}', fontsize=13, fontweight='bold')\n",
        "    ax.set_xlabel('Distortion Strength')\n",
        "    ax.set_ylabel('Quantile (q)')\n",
        "\n",
        "plt.suptitle('ğŸ“ˆ T-cKS Sensitivity Analysis', fontsize=15, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.3 í•µì‹¬ ê²°ê³¼ ìš”ì•½\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í•µì‹¬ ê²°ê³¼ ìš”ì•½: íƒì§€ ê°œì„ ìœ¨ ê³„ì‚°\n",
        "print(\"ğŸ“Š í•µì‹¬ ê²°ê³¼ ìš”ì•½ (q=0.95, strength=0.8)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for method in ['winsorization', 'thinning']:\n",
        "    print(f\"\\nğŸ”¹ {method.capitalize()}\")\n",
        "    \n",
        "    # ê¸°ì¤€ì„  (ì™œê³¡ ì—†ìŒ)\n",
        "    baseline = results_df[\n",
        "        (results_df['method'] == method) & \n",
        "        (results_df['strength'] == 0.0) & \n",
        "        (results_df['q'] == 0.95)\n",
        "    ][['mKS', 'cKS', 'T-cKS']].mean()\n",
        "    \n",
        "    # ì™œê³¡ í›„\n",
        "    distorted = results_df[\n",
        "        (results_df['method'] == method) & \n",
        "        (results_df['strength'] == 0.8) & \n",
        "        (results_df['q'] == 0.95)\n",
        "    ][['mKS', 'cKS', 'T-cKS']].mean()\n",
        "    \n",
        "    print(f\"   {'Metric':<10} {'Baseline':>12} {'Distorted':>12} {'Change':>12}\")\n",
        "    print(f\"   {'-'*10} {'-'*12} {'-'*12} {'-'*12}\")\n",
        "    \n",
        "    for metric in ['mKS', 'cKS', 'T-cKS']:\n",
        "        change = distorted[metric] - baseline[metric]\n",
        "        print(f\"   {metric:<10} {baseline[metric]:>12.4f} {distorted[metric]:>12.4f} {change:>+12.4f}\")\n",
        "    \n",
        "    # T-cKS vs cKS ê°œì„ ìœ¨\n",
        "    cks_change = distorted['cKS'] - baseline['cKS']\n",
        "    tcks_change = distorted['T-cKS'] - baseline['T-cKS']\n",
        "    \n",
        "    if cks_change > 0:\n",
        "        improvement = (tcks_change / cks_change - 1) * 100\n",
        "        print(f\"\\n   â­ T-cKSê°€ cKS ëŒ€ë¹„ {improvement:.1f}% ë” í° ë³€í™” ê°ì§€!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.4 ë…¼ë¬¸ìš© ìš”ì•½ í…Œì´ë¸”\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë…¼ë¬¸ìš© ìš”ì•½ í…Œì´ë¸” ìƒì„±\n",
        "summary_table = results_df.groupby(['method', 'q', 'strength']).agg({\n",
        "    'mKS': ['mean', 'std'],\n",
        "    'cKS': ['mean', 'std'],\n",
        "    'T-cKS': ['mean', 'std']\n",
        "}).round(4)\n",
        "\n",
        "# ì»¬ëŸ¼ëª… ì •ë¦¬\n",
        "summary_table.columns = [f'{col[0]}_{col[1]}' for col in summary_table.columns]\n",
        "summary_table = summary_table.reset_index()\n",
        "\n",
        "print(\"ğŸ“‹ ë…¼ë¬¸ìš© ìš”ì•½ í…Œì´ë¸” (q=0.95)\")\n",
        "display_df = summary_table[summary_table['q'] == 0.95][\n",
        "    ['method', 'strength', 'mKS_mean', 'cKS_mean', 'T-cKS_mean']\n",
        "].round(4)\n",
        "display_df.columns = ['Method', 'Strength', 'mKS', 'cKS', 'T-cKS']\n",
        "display_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. ê²°ê³¼ ì €ì¥\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "os.makedirs('results', exist_ok=True)\n",
        "\n",
        "# ì „ì²´ ê²°ê³¼ ì €ì¥\n",
        "results_df.to_csv('results/experiment_1_results.csv', index=False)\n",
        "print(\"âœ… ì „ì²´ ê²°ê³¼ ì €ì¥: results/experiment_1_results.csv\")\n",
        "\n",
        "# ìš”ì•½ í…Œì´ë¸” ì €ì¥\n",
        "summary_table.to_csv('results/summary_table.csv', index=False)\n",
        "print(\"âœ… ìš”ì•½ í…Œì´ë¸” ì €ì¥: results/summary_table.csv\")\n",
        "\n",
        "# ì‹¤í—˜ ì„¤ì • ì €ì¥\n",
        "import json\n",
        "config = {\n",
        "    'condition_col': CONDITION_COL,\n",
        "    'target_condition': TARGET_CONDITION,\n",
        "    'loss_col': LOSS_COL,\n",
        "    'min_tail_n': MIN_TAIL_N,\n",
        "    'methods': methods,\n",
        "    'strengths': strengths,\n",
        "    'q_values': q_values,\n",
        "    'n_seeds': len(seeds),\n",
        "    'total_samples': len(df)\n",
        "}\n",
        "\n",
        "with open('results/experiment_config.json', 'w') as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "print(\"âœ… ì‹¤í—˜ ì„¤ì • ì €ì¥: results/experiment_config.json\")\n",
        "\n",
        "print(\"\\nğŸ“ ì €ì¥ëœ íŒŒì¼ ëª©ë¡:\")\n",
        "for f in os.listdir('results'):\n",
        "    print(f\"   - results/{f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Experiment 2: Sensitivity Analysis\n",
        "\n",
        "q ê°’ì— ë”°ë¥¸ T-cKSì˜ ë¯¼ê°ë„ ë¶„ì„\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# q ê°’ë³„ ë¯¼ê°ë„ ë¶„ì„\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "for idx, method in enumerate(['winsorization', 'thinning']):\n",
        "    ax = axes[idx]\n",
        "    \n",
        "    # strength=0.8ë¡œ ê³ ì •í•˜ê³  që³„ ë¹„êµ\n",
        "    df_method = results_df[(results_df['method'] == method) & (results_df['strength'] == 0.8)]\n",
        "    grouped = df_method.groupby('q')[['mKS', 'cKS', 'T-cKS']].agg(['mean', 'std'])\n",
        "    \n",
        "    q_vals = grouped.index.values\n",
        "    x = np.arange(len(q_vals))\n",
        "    width = 0.25\n",
        "    \n",
        "    for i, (metric, color) in enumerate(COLORS.items()):\n",
        "        means = grouped[(metric, 'mean')].values\n",
        "        stds = grouped[(metric, 'std')].values\n",
        "        ax.bar(x + (i - 1) * width, means, width, yerr=stds, \n",
        "               label=metric, color=color, alpha=0.8, capsize=3)\n",
        "    \n",
        "    ax.set_xlabel('Quantile (q)', fontsize=12)\n",
        "    ax.set_ylabel('KS Distance', fontsize=12)\n",
        "    ax.set_title(f'{method.capitalize()} (strength=0.8)', fontsize=13, fontweight='bold')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels([f'{q}' for q in q_vals])\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.suptitle('ğŸ“Š Sensitivity to Quantile (q) Selection', fontsize=15, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. ê²°ë¡ \n",
        "\n",
        "### ì‹¤í—˜ ê²°ê³¼ ìš”ì•½\n",
        "\n",
        "ì´ ì‹¤í—˜ì„ í†µí•´ í™•ì¸ëœ ì£¼ìš” ê²°ê³¼:\n",
        "\n",
        "1. **mKS (Marginal KS)**: ì¡°ê±´ë¶€ ê·¹ë‹¨ ì†ì‹¤ ì™œê³¡ì— ê±°ì˜ ë°˜ì‘í•˜ì§€ ì•ŠìŒ\n",
        "2. **cKS (Conditional KS)**: ì œí•œì ì¸ ë°˜ì‘ - ì¡°ê±´ë³„ ì „ì²´ ë¶„í¬ë¥¼ ë¹„êµí•˜ë¯€ë¡œ tail ì™œê³¡ì´ í¬ì„ë¨\n",
        "3. **T-cKS (Tail-Conditional KS)**: ì¡°ê±´ë¶€ ê·¹ë‹¨ ì†ì‹¤ ì™œê³¡ì„ íš¨ê³¼ì ìœ¼ë¡œ íƒì§€ â­\n",
        "\n",
        "### ë…¼ë¬¸ì—ì„œ ì‚¬ìš©í•  ì£¼ìš” ê·¸ë˜í”„\n",
        "- ì™œê³¡ ê°•ë„ë³„ ë©”íŠ¸ë¦­ ë¹„êµ (Figure 1)\n",
        "- T-cKS íˆíŠ¸ë§µ (Figure 2)\n",
        "- q ë¯¼ê°ë„ ë¶„ì„ (Figure 3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ìµœì¢… ì‹¤í—˜ í†µê³„\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸ¯ ì‹¤í—˜ ì™„ë£Œ!\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nğŸ“Š ë°ì´í„°ì…‹: Allstate Claims Severity\")\n",
        "print(f\"   - ì´ ìƒ˜í”Œ: {len(df):,}\")\n",
        "print(f\"   - ì¡°ê±´ ë³€ìˆ˜: {CONDITION_COL}\")\n",
        "print(f\"   - ì™œê³¡ ëŒ€ìƒ: {TARGET_CONDITION}\")\n",
        "\n",
        "print(f\"\\nğŸ”¬ ì‹¤í—˜ ì„¤ì •:\")\n",
        "print(f\"   - ì™œê³¡ ë°©ë²•: {methods}\")\n",
        "print(f\"   - ì™œê³¡ ê°•ë„: {strengths}\")\n",
        "print(f\"   - q ê°’: {q_values}\")\n",
        "print(f\"   - ì´ ì‹¤í—˜ ìˆ˜: {len(results_df)}\")\n",
        "\n",
        "print(f\"\\nğŸ“ ì €ì¥ëœ ê²°ê³¼:\")\n",
        "print(f\"   - results/experiment_1_results.csv\")\n",
        "print(f\"   - results/summary_table.csv\")\n",
        "print(f\"   - results/experiment_config.json\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
